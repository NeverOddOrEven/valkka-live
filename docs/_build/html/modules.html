
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Modules &#8212; valkka_live  documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Copyright and License" href="license.html" />
    <link rel="prev" title="FAQ" href="faq.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="modules">
<h1>Modules<a class="headerlink" href="#modules" title="Permalink to this headline">¶</a></h1>
<div class="section" id="machine-vision">
<h2>Machine Vision<a class="headerlink" href="#machine-vision" title="Permalink to this headline">¶</a></h2>
<p>Once Valkka has decoded a frame from a certain camera, that decoded frame can be dumped to screen (to hundred windows if necessary) and passed to machine vision routines.  There is no overhead, as the stream from a certain camera is decoded only once.</p>
<p>Decoded frames can be pushed to machine vision routines that are programmed at the python level.  You can easily construct your own too.  At the moment, there are two schemes of plugging-in a python machine vision module.</p>
<p><strong>1. Using a python multiprocess.</strong>  Communication with the python multiprocess is done by passing frames through shared memory from the Valkka main process.</p>
<blockquote>
<div><ul class="simple">
<li>Use this always when you can embed your routine as a python module</li>
<li>Typical use-case: OpenCV</li>
</ul>
</div></blockquote>
<p><strong>2. Using an external python program.</strong>  Frames are passed to the external program through the filesystem.  Other communication is done through stdin and stdout.</p>
<blockquote>
<div><ul>
<li><p class="first">Use when your program is impossible to embed as a python module</p>
</li>
<li><p class="first">Say, when using keras machine vision running in a docker container</p>
</li>
<li><p class="first">Your program must conform to a certain base class, see:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">valkka_live</span><span class="o">/</span><span class="n">valkka</span><span class="o">/</span><span class="n">mvision</span><span class="o">/</span><span class="n">example_process1</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Each machine vision module appears as its own directory (the plugin scheme is indicated as well):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">valkka</span><span class="o">-</span><span class="n">live</span><span class="o">/</span><span class="n">valkka</span><span class="o">/</span><span class="n">mvision</span><span class="o">/</span>

    <span class="n">movement</span><span class="o">/</span>           <span class="n">simple</span> <span class="n">movement</span> <span class="n">detector</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">nix</span><span class="o">/</span>                <span class="n">demo</span> <span class="n">detector</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">alpr</span><span class="o">/</span>               <span class="n">OpenALPR</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yolo3</span><span class="o">/</span>              <span class="n">Yolo</span> <span class="n">v3</span> <span class="nb">object</span> <span class="n">detection</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yolo3tiny</span><span class="o">/</span>          <span class="n">Yolo</span> <span class="n">v3</span> <span class="n">Tiny</span> <span class="nb">object</span> <span class="n">detection</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">yolo2</span><span class="o">/</span>              <span class="n">Yolo</span> <span class="n">v2</span> <span class="nb">object</span> <span class="n">detection</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>You can create your own by copying any of the directories to a different name.  Then, study and edit the file <em>base.py</em> in that directory.  After that, you still have to register the module into:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">valkka</span><span class="o">-</span><span class="n">live</span><span class="o">/</span><span class="n">valkka</span><span class="o">/</span><span class="n">mvision</span><span class="o">/</span><span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>Before deploying your machine vision routine, you can test within the module file like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">valkka</span><span class="o">-</span><span class="n">live</span><span class="o">/</span><span class="n">valkka</span><span class="o">/</span><span class="n">mvision</span><span class="o">/</span><span class="n">movement</span>
<span class="n">python3</span> <span class="n">base</span><span class="o">.</span><span class="n">py</span> <span class="n">N</span>
</pre></div>
</div>
<p>where <em>N</em> is the test number.  Test number 5 in particular, lets you to test the machine vision module with video files (see each <em>base.py</em> for more information).</p>
<p>Before taking a detailed look into the provided example modules, keep in mind that the scheme used here for passing frames among processes with POSIX shared memory and semaphores is ok if you need around 1 frame per second.</p>
<p>This is sufficient for many applications.  However, if you want more serious a thing, say, 25 fps video analysis at higher resolution, you should implement your stuff at cpp level.  And only after that interface to Valkka (<a class="reference external" href="https://github.com/elsampsa/valkka-cpp-examples">this</a> could help).</p>
</div>
<div class="section" id="machine-vision-examples">
<h2>Machine Vision Examples<a class="headerlink" href="#machine-vision-examples" title="Permalink to this headline">¶</a></h2>
<p>Once you install the dependencies for each of the example modules listed below, they appear automagically in Valkka Live menu bar.</p>
<p>If you’re running Ubuntu 18 (bionic), you can use this command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">valkka</span><span class="o">-</span><span class="n">bionic</span><span class="o">-</span><span class="n">install</span>
</pre></div>
</div>
<p>to install dependencies of the machine vision modules (excluding Yolo object detection)</p>
<div class="section" id="movement-detector">
<h3>Movement Detector<a class="headerlink" href="#movement-detector" title="Permalink to this headline">¶</a></h3>
<p>This is an extremely simple demo, using OpenCV.  It reports when there is movement.  A good basis for using your own, OpenCV based module.</p>
<p>This module needs OpenCV installed.  See <a class="reference external" href="https://elsampsa.github.io/valkka-examples/_build/html/requirements.html#opencv">here</a>.</p>
</div>
<div class="section" id="nix">
<h3>Nix<a class="headerlink" href="#nix" title="Permalink to this headline">¶</a></h3>
<p>Demonstrates how to send frames to an external process.</p>
<p>Files are sent to a file in the “/tmp” directory, reading and writing frames is synchronized using communication through stdin and stdout.</p>
</div>
<div class="section" id="openalpr">
<h3>OpenALPR<a class="headerlink" href="#openalpr" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://www.openalpr.com">OpenALPR</a> is a popular OpenSource library for automatic license plate recognition.  We provide a bridge to it.</p>
<p>First of all <strong>DO NOT</strong> install the freemium OpenSource version available at the <a class="reference external" href="https://github.com/openalpr/openalpr">github repository</a>, as its outdated and buggy.  Instead, install the commercial version as instructed <a class="reference external" href="http://doc.openalpr.com/sdk.html">here</a>, i.e. like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bash</span> <span class="o">&lt;</span><span class="p">(</span><span class="n">curl</span> <span class="o">-</span><span class="n">s</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">deb</span><span class="o">.</span><span class="n">openalpr</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">install</span><span class="p">)</span>
</pre></div>
</div>
<p>You will also need a license key which you can get from here <a class="reference external" href="https://www.openalpr.com/on-premises.html">here</a>.  Place the key you obtain from the OpenALPR folks into</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">openalpr</span><span class="o">/</span><span class="n">license</span><span class="o">.</span><span class="n">conf</span>
</pre></div>
</div>
<p>Confirm that OpenALPR works with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">alpr</span> <span class="o">-</span><span class="n">c</span> <span class="n">eu</span> <span class="n">photo_of_your_car</span><span class="o">.</span><span class="n">jpg</span>
</pre></div>
</div>
<p>In order to make this work with python, you still have to do this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">echo</span> <span class="s1">&#39;deb https://deb.openalpr.com/bionic/ bionic main&#39;</span> <span class="o">|</span> <span class="n">sudo</span> <span class="n">tee</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">apt</span><span class="o">/</span><span class="n">sources</span><span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">d</span><span class="o">/</span><span class="n">openalpr</span><span class="o">.</span><span class="n">list</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">python3</span><span class="o">-</span><span class="n">openalpr</span>
</pre></div>
</div>
<p>(as for some reason that script provided by openalpr unsubscribes your from their repository)</p>
<p>Confirm that the python bindings work with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ipython3</span>
<span class="kn">from</span> <span class="nn">openalpr</span> <span class="k">import</span> <span class="n">Alpr</span>
</pre></div>
</div>
<p>That’s it!  Now “License Plate Recognition” should appear under “Machine Vision” in Valkka Live</p>
</div>
<div class="section" id="yolo-object-detection">
<h3>Yolo Object Detection<a class="headerlink" href="#yolo-object-detection" title="Permalink to this headline">¶</a></h3>
<p>Once you have installed and tested <a class="reference external" href="https://github.com/elsampsa/darknet-python">our Darknet python bindings</a>, the Yolo 3 object detector will appear in the Machine Vision plug-in menu.</p>
<p>Several Yolo versions are provided:</p>
<ul class="simple">
<li>Yolo v3 is the best, but a bit heavy, so it won’t work on a “commodity” laptop.  You need a hefty GPU with 2.5+ GB memory.</li>
<li>Yolo v2 is almost as good as Yolo v3, but needs less memory on the GPU</li>
<li>Yolo v3 Tiny works on the CPU as well and on a regular i7 laptop</li>
</ul>
</div>
</div>
<div class="section" id="creating-packages">
<h2>Creating Packages<a class="headerlink" href="#creating-packages" title="Permalink to this headline">¶</a></h2>
<p>You can create your own packages with machine vision modules using namespaces starting with <em>valkka.mvision</em>.</p>
<p>If you create, a namespace package to, say, namespace <em>valkka.mvision_myown</em>, and use the same conventions (directories, classnames, etc.) explained above for <em>valkka.mvision</em>, they will appear automagically in Valkka Live’s <em>Machine Vision</em> menus.</p>
<p>For creating namespace modules under <em>valkka.</em>, refer <a class="reference external" href="https://github.com/elsampsa/valkka-skeleton">here</a></p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">

<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<a href="index.html">
    <img class="logo" src="_static/valkka.png">
</a>

<p>Valkka Live - OpenSource Video Surveillance</p>
<!--
<a class="github-button" href="https://github.com/elsampsa/valkka-live" data-size="large" data-show-count="true" aria-label="Star elsampsa/valkka-live on GitHub">Star</a>
-->
<!--
<p>
  <iframe src="http://ghbtns.com/github-btn.html?user=elsampsa&repo=valkka-core&type=watch&count=true&size=large" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>
-->

<h3>Links</h3>
<ul>
  <!-- <li><a href="https://github.com/elsampsa/valkka-core"><i class="fab fa-github"></i> valkka-core @ GitHub</a></li>
  <li><a href="https://github.com/elsampsa/valkka-examples"><i class="fab fa-github"></i> valkka-examples @ GitHub</a></li>
  -->
  <li><a href="https://github.com/elsampsa/valkka-live"><i class="fab fa-github"></i> valkka-live @ GitHub</a></li>
  <li><a href="https://github.com/elsampsa/valkka-live/issues"><i class="fas fa-bug"></i> Issue Tracker</a></li>
  <!-- <li><a href="https://pypi.org/project/valkka-live/"><i class="fas fa-archive"></i> Package Repository</a></li> -->
  <li><a href="https://elsampsa.github.io/valkka-examples/"><i class="fas fa-cog"></i> valkka library</a></li>
  <li><a href="http://www.dasys.fi"><i class="fas fa-building"></i> Dasys Ltd.</a></li>
</ul>
<h3><a href="index.html">Table of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="requirements.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="manual.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#machine-vision">Machine Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="#machine-vision-examples">Machine Vision Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#movement-detector">Movement Detector</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nix">Nix</a></li>
<li class="toctree-l3"><a class="reference internal" href="#openalpr">OpenALPR</a></li>
<li class="toctree-l3"><a class="reference internal" href="#yolo-object-detection">Yolo Object Detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#creating-packages">Creating Packages</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="license.html">Copyright and License</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Authors</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018 Sampsa Riikonen.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/modules.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>